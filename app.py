import streamlit as st
import openai
import requests
import json
import time
import pandas as pd
import plotly.express as px
from datetime import datetime
import tiktoken
import os
from typing import List, Dict, Optional

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Chat é•œåƒç«™",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
.main-header {
    font-size: 3rem;
    font-weight: bold;
    text-align: center;
    background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 2rem;
}

.feature-card {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
    border-left: 4px solid #4ECDC4;
}

.status-good {
    color: #28a745;
    font-weight: bold;
}

.status-error {
    color: #dc3545;
    font-weight: bold;
}

.chat-message {
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
}

.user-message {
    background-color: #e3f2fd;
    border-left: 4px solid #2196f3;
}

.assistant-message {
    background-color: #f3e5f5;
    border-left: 4px solid #9c27b0;
}
</style>
""", unsafe_allow_html=True)

class AIService:
    def __init__(self):
        self.base_url = None
        self.api_key = None
        self.client = None
        self.available_models = []
        
    def initialize_client(self, api_key: str, base_url: str):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            self.api_key = api_key
            self.base_url = base_url
            self.client = openai.OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            return True
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
            return False
    
    def fetch_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            if not self.client:
                return []
            
            response = self.client.models.list()
            models = [model.id for model in response.data]
            self.available_models = sorted(models)
            return self.available_models
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥çŠ¶æ€"""
        try:
            if not self.client:
                return False
            
            # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨æ¥æµ‹è¯•è¿æ¥
            self.client.models.list()
            return True
        except Exception as e:
            st.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def chat_completion(self, messages: List[Dict], model: str, **kwargs) -> Optional[str]:
        """å‘é€èŠå¤©è¯·æ±‚"""
        try:
            if not self.client:
                return None
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                **kwargs
            )
            return response.choices[0].message.content
        except Exception as e:
            st.error(f"èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")
            return None

def count_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    """è®¡ç®—tokenæ•°é‡"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except:
        # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼Œä½¿ç”¨è¿‘ä¼¼è®¡ç®—
        return len(text.split()) * 1.3

def get_preset_prompts() -> Dict[str, str]:
    """è·å–é¢„è®¾æç¤ºè¯"""
    return {
        "ğŸ’¼ ä¸“ä¸šåŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨å‡†ç¡®ã€æ¸…æ™°ã€æœ‰æ¡ç†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚",
        "ğŸ¨ åˆ›æ„å†™ä½œ": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„å†™ä½œåŠ©æ‰‹ï¼Œè¯·å¸®åŠ©ç”¨æˆ·è¿›è¡Œåˆ›æ„å†™ä½œï¼ŒåŒ…æ‹¬æ•…äº‹ã€è¯—æ­Œã€å‰§æœ¬ç­‰ã€‚",
        "ğŸ’» ç¼–ç¨‹ä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç¼–ç¨‹ä¸“å®¶ï¼Œç²¾é€šå¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œè¯·å¸®åŠ©ç”¨æˆ·è§£å†³ç¼–ç¨‹é—®é¢˜ã€‚",
        "ğŸ“š å­¦ä¹ å¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„å­¦ä¹ å¯¼å¸ˆï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå¤æ‚æ¦‚å¿µï¼Œå¹¶æä¾›å­¦ä¹ å»ºè®®ã€‚",
        "ğŸŒ ç¿»è¯‘åŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ç¿»è¯‘ç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œå¹¶è§£é‡Šè¯­è¨€ç»†èŠ‚ã€‚",
        "ğŸ§  åˆ†æä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ªé€»è¾‘æ€ç»´æ¸…æ™°çš„åˆ†æä¸“å®¶ï¼Œè¯·å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œæ·±å…¥åˆ†æå¹¶æä¾›è§è§£ã€‚",
        "ğŸ¯ äº§å“ç»ç†": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„äº§å“ç»ç†ï¼Œè¯·ä»äº§å“è§’åº¦åˆ†æé—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚",
        "ğŸ“Š æ•°æ®åˆ†æå¸ˆ": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œè¯·å¸®åŠ©ç”¨æˆ·åˆ†ææ•°æ®å¹¶æä¾›æ´å¯Ÿã€‚"
    }

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'ai_service' not in st.session_state:
        st.session_state.ai_service = AIService()
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if 'conversation_count' not in st.session_state:
        st.session_state.conversation_count = 0
    
    if 'total_tokens' not in st.session_state:
        st.session_state.total_tokens = 0
    
    if 'settings' not in st.session_state:
        st.session_state.settings = {
            'temperature': 0.7,
            'max_tokens': 2048,
            'top_p': 1.0,
            'frequency_penalty': 0.0,
            'presence_penalty': 0.0
        }

def main():
    initialize_session_state()
    
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¤– AI Chat é•œåƒç«™</h1>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®è®¾ç½®")
        
        # APIé…ç½®
        st.subheader("ğŸ”‘ API é…ç½®")
        api_key = st.text_input("API Key", type="password", value="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")
        base_url = st.text_input("Base URL", value="https://api.openai.com/v1")
        
        if st.button("ğŸ”„ è¿æ¥æµ‹è¯•"):
            if api_key and base_url:
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    if st.session_state.ai_service.initialize_client(api_key, base_url):
                        if st.session_state.ai_service.test_connection():
                            st.success("âœ… è¿æ¥æˆåŠŸï¼")
                            # è·å–æ¨¡å‹åˆ—è¡¨
                            models = st.session_state.ai_service.fetch_models()
                            if models:
                                st.success(f"âœ… è·å–åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹")
                        else:
                            st.error("âŒ è¿æ¥å¤±è´¥")
            else:
                st.warning("âš ï¸ è¯·å¡«å†™API Keyå’ŒBase URL")
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¯ æ¨¡å‹é€‰æ‹©")
        if st.session_state.ai_service.available_models:
            selected_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                st.session_state.ai_service.available_models,
                index=0 if st.session_state.ai_service.available_models else None
            )
        else:
            selected_model = st.text_input("æ¨¡å‹åç§°", value="gpt-3.5-turbo")
            if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨"):
                if st.session_state.ai_service.client:
                    models = st.session_state.ai_service.fetch_models()
                    if models:
                        st.rerun()
        
        # é«˜çº§è®¾ç½®
        st.subheader("ğŸ› ï¸ é«˜çº§è®¾ç½®")
        with st.expander("å‚æ•°è°ƒèŠ‚"):
            st.session_state.settings['temperature'] = st.slider(
                "Temperature (åˆ›é€ æ€§)", 0.0, 2.0, 
                st.session_state.settings['temperature'], 0.1
            )
            st.session_state.settings['max_tokens'] = st.slider(
                "Max Tokens", 1, 4096, 
                st.session_state.settings['max_tokens']
            )
            st.session_state.settings['top_p'] = st.slider(
                "Top P", 0.0, 1.0, 
                st.session_state.settings['top_p'], 0.1
            )
            st.session_state.settings['frequency_penalty'] = st.slider(
                "Frequency Penalty", -2.0, 2.0, 
                st.session_state.settings['frequency_penalty'], 0.1
            )
            st.session_state.settings['presence_penalty'] = st.slider(
                "Presence Penalty", -2.0, 2.0, 
                st.session_state.settings['presence_penalty'], 0.1
            )
        
        # ç»Ÿè®¡ä¿¡æ¯
        st.subheader("ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
        st.metric("å¯¹è¯æ¬¡æ•°", st.session_state.conversation_count)
        st.metric("æ€»Tokenæ•°", st.session_state.total_tokens)
        
        # æ“ä½œæŒ‰é’®
        st.subheader("ğŸ”§ æ“ä½œ")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.session_state.conversation_count = 0
            st.session_state.total_tokens = 0
            st.rerun()
        
        if st.button("ğŸ’¾ å¯¼å‡ºå¯¹è¯"):
            if st.session_state.chat_history:
                export_data = {
                    "timestamp": datetime.now().isoformat(),
                    "conversation_count": st.session_state.conversation_count,
                    "total_tokens": st.session_state.total_tokens,
                    "chat_history": st.session_state.chat_history
                }
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½JSONæ–‡ä»¶",
                    json.dumps(export_data, ensure_ascii=False, indent=2),
                    file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ å¯¹è¯åŒºåŸŸ")
        
        # é¢„è®¾æç¤ºè¯
        st.subheader("ğŸ­ é¢„è®¾è§’è‰²")
        preset_prompts = get_preset_prompts()
        
        cols = st.columns(4)
        for i, (name, prompt) in enumerate(preset_prompts.items()):
            with cols[i % 4]:
                if st.button(name, key=f"preset_{i}"):
                    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
                    if not st.session_state.chat_history or st.session_state.chat_history[0]["role"] != "system":
                        st.session_state.chat_history.insert(0, {
                            "role": "system",
                            "content": prompt,
                            "timestamp": datetime.now().strftime("%H:%M:%S")
                        })
                    else:
                        st.session_state.chat_history[0]["content"] = prompt
                    st.rerun()
        
        # è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
        custom_system_prompt = st.text_area(
            "ğŸ¯ è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯",
            placeholder="è¾“å…¥è‡ªå®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯æ¥å®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º...",
            height=100
        )
        
        if st.button("ğŸ¯ è®¾ç½®ç³»ç»Ÿæç¤ºè¯") and custom_system_prompt:
            if not st.session_state.chat_history or st.session_state.chat_history[0]["role"] != "system":
                st.session_state.chat_history.insert(0, {
                    "role": "system",
                    "content": custom_system_prompt,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                })
            else:
                st.session_state.chat_history[0]["content"] = custom_system_prompt
            st.success("âœ… ç³»ç»Ÿæç¤ºè¯å·²è®¾ç½®")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        st.subheader("ğŸ“ å¯¹è¯å†å²")
        chat_container = st.container()
        
        with chat_container:
            for i, message in enumerate(st.session_state.chat_history):
                if message["role"] == "system":
                    with st.expander(f"ğŸ¯ ç³»ç»Ÿæç¤ºè¯ ({message.get('timestamp', '')})"):
                        st.write(message["content"])
                elif message["role"] == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>ğŸ‘¤ ç”¨æˆ· ({message.get('timestamp', '')}):</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>ğŸ¤– åŠ©æ‰‹ ({message.get('timestamp', '')}):</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
        
        # ç”¨æˆ·è¾“å…¥
        st.subheader("ğŸ’­ å‘é€æ¶ˆæ¯")
        
        # å¤šç§è¾“å…¥æ–¹å¼
        input_method = st.radio("è¾“å…¥æ–¹å¼", ["ğŸ’¬ æ™®é€šè¾“å…¥", "ğŸ“ å¤šè¡Œè¾“å…¥", "ğŸ¤ è¯­éŸ³è¾“å…¥(æš‚æœªå®ç°)"], horizontal=True)
        
        user_input = ""
        if input_method == "ğŸ’¬ æ™®é€šè¾“å…¥":
            user_input = st.text_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯:", key="user_input_text")
        elif input_method == "ğŸ“ å¤šè¡Œè¾“å…¥":
            user_input = st.text_area("è¾“å…¥æ‚¨çš„æ¶ˆæ¯:", height=150, key="user_input_area")
        
        # å¿«é€Ÿæç¤ºè¯
        st.write("ğŸš€ å¿«é€Ÿæç¤ºè¯:")
        quick_prompts = [
            "è¯·æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„å¯¹è¯",
            "è¯·ç»™æˆ‘ä¸€äº›å»ºè®®",
            "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
            "è¯·ä¸¾ä¸ªä¾‹å­è¯´æ˜",
            "è¯·åˆ—å‡ºè¦ç‚¹",
            "è¯·æ¢ä¸ªè§’åº¦åˆ†æ"
        ]
        
        cols = st.columns(3)
        for i, prompt in enumerate(quick_prompts):
            with cols[i % 3]:
                if st.button(prompt, key=f"quick_{i}"):
                    user_input = prompt
        
        # å‘é€æŒ‰é’®
        col_send, col_clear = st.columns([1, 1])
        with col_send:
            send_clicked = st.button("ğŸš€ å‘é€æ¶ˆæ¯", type="primary")
        with col_clear:
            if st.button("ğŸ§¹ æ¸…ç©ºè¾“å…¥"):
                st.rerun()
        
        # å¤„ç†å‘é€æ¶ˆæ¯
        if send_clicked and user_input and st.session_state.ai_service.client:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
            
            # å‡†å¤‡å‘é€ç»™AIçš„æ¶ˆæ¯
            messages_for_ai = [msg for msg in st.session_state.chat_history if msg["role"] in ["system", "user", "assistant"]]
            messages_for_ai = [{"role": msg["role"], "content": msg["content"]} for msg in messages_for_ai]
            
            # å‘é€è¯·æ±‚
            with st.spinner("ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­..."):
                response = st.session_state.ai_service.chat_completion(
                    messages=messages_for_ai,
                    model=selected_model,
                    **st.session_state.settings
                )
                
                if response:
                    # æ·»åŠ AIå›å¤
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": response,
                        "timestamp": datetime.now().strftime("%H:%M:%S")
                    })
                    
                    # æ›´æ–°ç»Ÿè®¡
                    st.session_state.conversation_count += 1
                    user_tokens = count_tokens(user_input, selected_model)
                    response_tokens = count_tokens(response, selected_model)
                    st.session_state.total_tokens += user_tokens + response_tokens
                    
                    st.rerun()
        elif send_clicked and not st.session_state.ai_service.client:
            st.error("âŒ è¯·å…ˆé…ç½®å¹¶æµ‹è¯•APIè¿æ¥")
        elif send_clicked and not user_input:
            st.warning("âš ï¸ è¯·è¾“å…¥æ¶ˆæ¯å†…å®¹")
    
    with col2:
        st.header("ğŸ“Š åŠŸèƒ½é¢æ¿")
        
        # è¿æ¥çŠ¶æ€
        st.subheader("ğŸ”Œ è¿æ¥çŠ¶æ€")
        if st.session_state.ai_service.client:
            st.markdown('<p class="status-good">âœ… å·²è¿æ¥</p>', unsafe_allow_html=True)
            if st.session_state.ai_service.available_models:
                st.write(f"ğŸ¯ å¯ç”¨æ¨¡å‹: {len(st.session_state.ai_service.available_models)}ä¸ª")
        else:
            st.markdown('<p class="status-error">âŒ æœªè¿æ¥</p>', unsafe_allow_html=True)
        
        # Tokenä½¿ç”¨æƒ…å†µå›¾è¡¨
        if st.session_state.total_tokens > 0:
            st.subheader("ğŸ“ˆ Tokenä½¿ç”¨è¶‹åŠ¿")
            # ç®€å•çš„ä½¿ç”¨ç»Ÿè®¡ï¼ˆè¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºæ›´è¯¦ç»†çš„å›¾è¡¨ï¼‰
            fig = px.pie(
                values=[st.session_state.total_tokens, max(10000 - st.session_state.total_tokens, 0)],
                names=['å·²ä½¿ç”¨', 'å‰©ä½™'],
                title="Tokenä½¿ç”¨æƒ…å†µ"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # æ¨¡å‹ä¿¡æ¯
        st.subheader("ğŸ¤– å½“å‰æ¨¡å‹")
        if 'selected_model' in locals():
            st.info(f"ğŸ“± **æ¨¡å‹**: {selected_model}")
            st.info(f"ğŸŒ¡ï¸ **Temperature**: {st.session_state.settings['temperature']}")
            st.info(f"ğŸ“ **Max Tokens**: {st.session_state.settings['max_tokens']}")
        
        # å®ç”¨å·¥å…·
        st.subheader("ğŸ› ï¸ å®ç”¨å·¥å…·")
        
        with st.expander("ğŸ“Š å¯¹è¯åˆ†æ"):
            if st.session_state.chat_history:
                user_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "user"])
                assistant_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "assistant"])
                
                st.write(f"ğŸ‘¤ ç”¨æˆ·æ¶ˆæ¯: {user_messages}")
                st.write(f"ğŸ¤– åŠ©æ‰‹å›å¤: {assistant_messages}")
                st.write(f"ğŸ’¬ æ€»æ¶ˆæ¯æ•°: {len(st.session_state.chat_history)}")
                
                # å­—ç¬¦ç»Ÿè®¡
                total_chars = sum(len(msg["content"]) for msg in st.session_state.chat_history)
                st.write(f"ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars}")
        
        with st.expander("ğŸ¨ ä¸»é¢˜è®¾ç½®"):
            theme = st.selectbox("é€‰æ‹©ä¸»é¢˜", ["é»˜è®¤", "æ·±è‰²", "æµ…è‰²"])
            if theme != "é»˜è®¤":
                st.info("ä¸»é¢˜åŠŸèƒ½å¼€å‘ä¸­...")
        
        with st.expander("ğŸ“‹ å¿«æ·æ“ä½œ"):
            if st.button("ğŸ“‹ å¤åˆ¶æœ€åå›å¤"):
                if st.session_state.chat_history:
                    last_assistant_msg = None
                    for msg in reversed(st.session_state.chat_history):
                        if msg["role"] == "assistant":
                            last_assistant_msg = msg["content"]
                            break
                    if last_assistant_msg:
                        st.code(last_assistant_msg)
                        st.success("âœ… å†…å®¹å·²æ˜¾ç¤ºï¼Œå¯æ‰‹åŠ¨å¤åˆ¶")
            
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆå›å¤"):
                if (st.session_state.chat_history and 
                    st.session_state.chat_history[-1]["role"] == "assistant"):
                    # ç§»é™¤æœ€åçš„åŠ©æ‰‹å›å¤
                    st.session_state.chat_history.pop()
                    st.success("âœ… å·²ç§»é™¤æœ€åå›å¤ï¼Œè¯·é‡æ–°å‘é€æ¶ˆæ¯")
        
        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
        st.write(f"ğŸ•’ å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        st.write(f"ğŸ·ï¸ ç‰ˆæœ¬: v1.0.0")
        st.write(f"âš¡ Streamlit: {st.__version__}")

if __name__ == "__main__":
    main()
