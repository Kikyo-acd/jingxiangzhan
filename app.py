import streamlit as st
import requests
import time
import json
import random
from datetime import datetime

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIæ™ºèƒ½å¯¹è¯å¹³å°",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

def apply_styles():
    """åº”ç”¨æ ·å¼å’Œæœ¬åœ°å­˜å‚¨JavaScript"""
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    /* å…¨å±€æ ·å¼ */
    .stApp {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        font-family: 'Inter', sans-serif;
    }
    
    /* ä¸»å®¹å™¨ */
    .main .block-container {
        padding: 2rem 1rem;
        max-width: 1200px;
        margin: 0 auto;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8fafc 0%, #e2e8f0 100%);
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-family: 'Inter', sans-serif;
        font-size: 2.5rem;
        font-weight: 700;
        text-align: center;
        margin: 2rem 0 1rem 0;
        background: linear-gradient(135deg, #3b82f6, #8b5cf6);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .subtitle {
        text-align: center;
        color: #64748b;
        font-size: 1.1rem;
        margin-bottom: 2rem;
        font-weight: 400;
    }
    
    /* å¡ç‰‡å®¹å™¨ */
    .card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        border: 1px solid #e2e8f0;
        transition: all 0.2s ease;
    }
    
    /* æ¶ˆæ¯æ ·å¼ */
    .user-message {
        background: linear-gradient(135deg, #3b82f6, #1d4ed8);
        color: white;
        padding: 1rem 1.2rem;
        border-radius: 18px 18px 4px 18px;
        margin: 0.8rem 0;
        margin-left: auto;
        max-width: 70%;
        font-weight: 500;
        box-shadow: 0 2px 8px rgba(59, 130, 246, 0.3);
        word-wrap: break-word;
    }
    
    .ai-message {
        background: #f8fafc;
        border: 1px solid #e2e8f0;
        color: #334155;
        padding: 1rem 1.2rem;
        border-radius: 18px 18px 18px 4px;
        margin: 0.8rem 0;
        margin-right: auto;
        max-width: 70%;
        line-height: 1.6;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        word-wrap: break-word;
    }
    
    .message-time {
        font-size: 0.75rem;
        color: rgba(255,255,255,0.7);
        margin-top: 0.5rem;
    }
    
    .ai-message .message-time {
        color: #94a3b8;
    }
    
    .message-model {
        font-size: 0.8rem;
        color: #7c3aed;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    
    /* æ¨¡å‹é€‰æ‹©å¡ç‰‡ */
    .model-card {
        background: white;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        cursor: pointer;
        transition: all 0.2s ease;
    }
    
    .model-card:hover {
        border-color: #3b82f6;
        box-shadow: 0 2px 8px rgba(59, 130, 246, 0.2);
    }
    
    .model-card.selected {
        border-color: #3b82f6;
        background: #eff6ff;
        box-shadow: 0 2px 8px rgba(59, 130, 246, 0.3);
    }
    
    .model-name {
        font-weight: 600;
        color: #1e293b;
        margin-bottom: 0.25rem;
    }
    
    .model-description {
        font-size: 0.85rem;
        color: #64748b;
        margin-bottom: 0.5rem;
        line-height: 1.4;
    }
    
    .model-tags {
        display: flex;
        gap: 0.3rem;
        flex-wrap: wrap;
    }
    
    .model-tag {
        background: #f1f5f9;
        color: #475569;
        padding: 0.2rem 0.5rem;
        border-radius: 4px;
        font-size: 0.7rem;
        font-weight: 500;
    }
    
    .model-tag.premium { background: #fef3c7; color: #92400e; }
    .model-tag.fast { background: #d1fae5; color: #065f46; }
    .model-tag.recommended { background: #ddd6fe; color: #6b21a8; }
    
    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        padding: 0.5rem 1rem;
        border-radius: 8px;
        font-size: 0.9rem;
        font-weight: 500;
        margin: 0.5rem 0;
    }
    
    .status-connected {
        background: #f0fdf4;
        border: 1px solid #bbf7d0;
        color: #166534;
    }
    
    .status-disconnected {
        background: #fef2f2;
        border: 1px solid #fecaca;
        color: #dc2626;
    }
    
    .status-dot {
        width: 8px;
        height: 8px;
        border-radius: 50%;
    }
    
    .dot-online {
        background: #22c55e;
        box-shadow: 0 0 0 2px rgba(34, 197, 94, 0.2);
    }
    
    .dot-offline {
        background: #ef4444;
        box-shadow: 0 0 0 2px rgba(239, 68, 68, 0.2);
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        border: 1px solid #d1d5db !important;
        border-radius: 8px !important;
        padding: 0.75rem !important;
        font-size: 1rem !important;
        background: white !important;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #3b82f6 !important;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1) !important;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #3b82f6, #1d4ed8) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.6rem 1.2rem !important;
        font-weight: 500 !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 2px 4px rgba(59, 130, 246, 0.2) !important;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #1d4ed8, #1e40af) !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 8px rgba(59, 130, 246, 0.3) !important;
    }
    
    /* åŠ è½½åŠ¨ç”» */
    .typing-indicator {
        display: flex;
        align-items: center;
        gap: 0.5rem;
        padding: 1rem;
        color: #64748b;
        font-style: italic;
    }
    
    .typing-dots {
        display: flex;
        gap: 4px;
    }
    
    .typing-dot {
        width: 6px;
        height: 6px;
        border-radius: 50%;
        background: #94a3b8;
        animation: typingBounce 1.4s ease-in-out infinite;
    }
    
    .typing-dot:nth-child(1) { animation-delay: 0ms; }
    .typing-dot:nth-child(2) { animation-delay: 160ms; }
    .typing-dot:nth-child(3) { animation-delay: 320ms; }
    
    @keyframes typingBounce {
        0%, 60%, 100% { transform: translateY(0); }
        30% { transform: translateY(-8px); }
    }
    
    /* éšè—é»˜è®¤å…ƒç´  */
    #MainMenu, .stDeployButton, footer { visibility: hidden; }
    
    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .main-title { font-size: 2rem; }
        .user-message, .ai-message { max-width: 90%; }
    }
    </style>
    
    <script>
    // æœ¬åœ°å­˜å‚¨ç®¡ç†
    window.ChatStorage = {
        // ä¿å­˜èŠå¤©æ•°æ®
        save: function(data) {
            try {
                const chatData = {
                    messages: data.messages || [],
                    apiKey: data.apiKey || '',
                    selectedModel: data.selectedModel || 'gpt-4o-mini',
                    conversationCount: data.conversationCount || 0,
                    lastSaved: new Date().toISOString()
                };
                localStorage.setItem('ai_chat_data', JSON.stringify(chatData));
                console.log('âœ… èŠå¤©æ•°æ®å·²ä¿å­˜', chatData.messages.length + ' æ¡æ¶ˆæ¯');
                return true;
            } catch(e) {
                console.error('âŒ ä¿å­˜å¤±è´¥:', e);
                return false;
            }
        },
        
        // åŠ è½½èŠå¤©æ•°æ®
        load: function() {
            try {
                const data = localStorage.getItem('ai_chat_data');
                if (data) {
                    const parsed = JSON.parse(data);
                    console.log('âœ… å·²åŠ è½½èŠå¤©æ•°æ®', parsed.messages.length + ' æ¡æ¶ˆæ¯');
                    return parsed;
                }
                return null;
            } catch(e) {
                console.error('âŒ åŠ è½½å¤±è´¥:', e);
                return null;
            }
        },
        
        // æ¸…ç©ºæ•°æ®
        clear: function() {
            try {
                localStorage.removeItem('ai_chat_data');
                console.log('âœ… èŠå¤©æ•°æ®å·²æ¸…ç©º');
                return true;
            } catch(e) {
                console.error('âŒ æ¸…ç©ºå¤±è´¥:', e);
                return false;
            }
        },
        
        // è·å–å­˜å‚¨å¤§å°
        getSize: function() {
            try {
                const data = localStorage.getItem('ai_chat_data');
                return data ? (data.length / 1024).toFixed(1) + 'KB' : '0KB';
            } catch(e) {
                return 'æœªçŸ¥';
            }
        }
    };
    
    // é¡µé¢åŠ è½½æ—¶å°è¯•æ¢å¤æ•°æ®
    window.addEventListener('load', function() {
        const savedData = window.ChatStorage.load();
        if (savedData && savedData.messages.length > 0) {
            console.log('ğŸ”„ å‘ç°æœ¬åœ°èŠå¤©è®°å½•ï¼Œå‡†å¤‡æ¢å¤...');
            // è§¦å‘è‡ªå®šä¹‰äº‹ä»¶é€šçŸ¥Streamlit
            window.dispatchEvent(new CustomEvent('chatDataFound', { 
                detail: savedData 
            }));
        }
    });
    
    // è‡ªåŠ¨ä¿å­˜å‡½æ•°
    window.autoSaveChatData = function(messages, apiKey, selectedModel, conversationCount) {
        return window.ChatStorage.save({
            messages: messages,
            apiKey: apiKey,
            selectedModel: selectedModel,
            conversationCount: conversationCount
        });
    };
    </script>
    """, unsafe_allow_html=True)

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        'chat_messages': [],
        'github_api_key': '',
        'available_models': [],
        'selected_model': 'gpt-4o-mini',
        'models_loaded': False,
        'conversation_count': 0,
        'auto_save_enabled': True,
        'data_restored': False
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def get_all_supported_models():
    """è·å–æ‰€æœ‰æ”¯æŒçš„AIæ¨¡å‹"""
    return [
        {
            'id': 'gpt-4o',
            'name': 'GPT-4o',
            'description': 'OpenAIæœ€æ–°çš„GPT-4 Omniæ¨¡å‹ï¼Œå…·å¤‡å¼ºå¤§çš„å¤šæ¨¡æ€èƒ½åŠ›å’Œç†è§£åŠ›',
            'tags': ['å¤šæ¨¡æ€', 'æœ€æ–°', 'é«˜è´¨é‡']
        },
        {
            'id': 'gpt-4o-mini',
            'name': 'GPT-4o Mini',
            'description': 'è½»é‡åŒ–ç‰ˆæœ¬çš„GPT-4oï¼Œå“åº”é€Ÿåº¦å¿«ï¼Œæˆæœ¬æ›´ä½ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯',
            'tags': ['å¿«é€Ÿ', 'ç»æµ', 'æ¨è']
        },
        {
            'id': 'gpt-4-turbo',
            'name': 'GPT-4 Turbo',
            'description': 'OpenAIçš„å¢å¼ºç‰ˆGPT-4ï¼Œæ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼Œå¤„ç†èƒ½åŠ›å¼º',
            'tags': ['é•¿ä¸Šä¸‹æ–‡', 'ç¨³å®š', 'å¼ºå¤§']
        },
        {
            'id': 'gpt-3.5-turbo',
            'name': 'GPT-3.5 Turbo',
            'description': 'OpenAIçš„ç»å…¸æ¨¡å‹ï¼Œåœ¨æ€§èƒ½å’Œæˆæœ¬ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡',
            'tags': ['ç»å…¸', 'å¹³è¡¡', 'å¯é ']
        },
        {
            'id': 'claude-3-5-sonnet',
            'name': 'Claude 3.5 Sonnet',
            'description': 'Anthropicæœ€æ–°çš„Claudeæ¨¡å‹ï¼Œæ“…é•¿åˆ†æã€æ¨ç†å’Œåˆ›ä½œ',
            'tags': ['åˆ†æ', 'æ¨ç†', 'åˆ›ä½œ']
        },
        {
            'id': 'claude-3-haiku',
            'name': 'Claude 3 Haiku',
            'description': 'Claudeç³»åˆ—ä¸­é€Ÿåº¦æœ€å¿«çš„æ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿå“åº”',
            'tags': ['å¿«é€Ÿ', 'Anthropic', 'è½»é‡']
        },
        {
            'id': 'llama-3.1-405b-instruct',
            'name': 'Llama 3.1 405B',
            'description': 'Metaæœ€å¤§è§„æ¨¡çš„å¼€æºæ¨¡å‹ï¼Œåœ¨æ¨ç†å’Œæ•°å­¦æ–¹é¢è¡¨ç°ä¼˜å¼‚',
            'tags': ['å¼€æº', 'å¤§æ¨¡å‹', 'æ¨ç†']
        },
        {
            'id': 'llama-3.1-70b-instruct',
            'name': 'Llama 3.1 70B',
            'description': 'Metaçš„ä¸­ç­‰è§„æ¨¡æ¨¡å‹ï¼Œå¹³è¡¡äº†æ€§èƒ½å’Œæ•ˆç‡',
            'tags': ['å¼€æº', 'å¹³è¡¡', 'Meta']
        },
        {
            'id': 'llama-3.1-8b-instruct',
            'name': 'Llama 3.1 8B',
            'description': 'Metaçš„è½»é‡çº§æ¨¡å‹ï¼Œå“åº”é€Ÿåº¦æå¿«',
            'tags': ['å¼€æº', 'è½»é‡', 'å¿«é€Ÿ']
        },
        {
            'id': 'qwen-2.5-72b-instruct',
            'name': 'Qwen 2.5 72B',
            'description': 'é˜¿é‡Œå·´å·´é€šä¹‰åƒé—®æœ€æ–°æ¨¡å‹ï¼Œä¸­æ–‡ç†è§£èƒ½åŠ›å¼º',
            'tags': ['ä¸­æ–‡ä¼˜åŒ–', 'é˜¿é‡Œå·´å·´', 'æœ€æ–°']
        },
        {
            'id': 'qwen-2.5-32b-instruct',
            'name': 'Qwen 2.5 32B',
            'description': 'é€šä¹‰åƒé—®ä¸­ç­‰è§„æ¨¡æ¨¡å‹ï¼Œä¸­è‹±æ–‡åŒè¯­èƒ½åŠ›å‡ºè‰²',
            'tags': ['ä¸­æ–‡', 'åŒè¯­', 'é€šä¹‰']
        },
        {
            'id': 'qwen-2.5-7b-instruct',
            'name': 'Qwen 2.5 7B',
            'description': 'é€šä¹‰åƒé—®è½»é‡çº§æ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿä¸­æ–‡å¯¹è¯',
            'tags': ['ä¸­æ–‡', 'è½»é‡', 'å¿«é€Ÿ']
        },
        {
            'id': 'mistral-large-2407',
            'name': 'Mistral Large',
            'description': 'Mistral AIçš„å¤§å‹æ¨¡å‹ï¼Œå¤šè¯­è¨€èƒ½åŠ›å¼º',
            'tags': ['å¤šè¯­è¨€', 'Mistral', 'æ¬§æ´²']
        },
        {
            'id': 'mistral-small',
            'name': 'Mistral Small',
            'description': 'Mistral AIçš„è½»é‡çº§æ¨¡å‹ï¼Œæˆæœ¬æ•ˆç›Šé«˜',
            'tags': ['è½»é‡', 'ç»æµ', 'Mistral']
        }
    ]

def test_model_availability(api_key, model_id):
    """æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§"""
    if not api_key:
        return False
        
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    
    payload = {
        "messages": [{"role": "user", "content": "hi"}],
        "model": model_id,
        "max_tokens": 5
    }
    
    try:
        response = requests.post(
            "https://models.inference.ai.azure.com/chat/completions",
            headers=headers,
            json=payload,
            timeout=10
        )
        return response.status_code == 200
    except:
        return False

def save_chat_data():
    """ä¿å­˜èŠå¤©æ•°æ®åˆ°æœ¬åœ°å­˜å‚¨"""
    if st.session_state.get('auto_save_enabled', True):
        # å‡†å¤‡æ•°æ®
        messages_data = []
        for msg in st.session_state.chat_messages:
            messages_data.append({
                'role': msg['role'],
                'content': msg['content'],
                'timestamp': msg.get('timestamp', time.time()),
                'model': msg.get('model', 'unknown')
            })
        
        # æ‰§è¡ŒJavaScriptä¿å­˜
        st.markdown(f"""
        <script>
        if (window.autoSaveChatData) {{
            const success = window.autoSaveChatData(
                {json.dumps(messages_data)},
                "{st.session_state.github_api_key}",
                "{st.session_state.selected_model}",
                {st.session_state.conversation_count}
            );
            if (success) {{
                console.log("ğŸ’¾ è‡ªåŠ¨ä¿å­˜æˆåŠŸ");
            }}
        }}
        </script>
        """, unsafe_allow_html=True)

def restore_chat_data():
    """ä»æœ¬åœ°å­˜å‚¨æ¢å¤èŠå¤©æ•°æ®"""
    if not st.session_state.get('data_restored', False):
        st.session_state.data_restored = True
        
        # å°è¯•ä»æœ¬åœ°å­˜å‚¨æ¢å¤
        st.markdown("""
        <script>
        setTimeout(() => {
            const savedData = window.ChatStorage.load();
            if (savedData && savedData.messages && savedData.messages.length > 0) {
                // æ˜¾ç¤ºæ¢å¤æç¤º
                const event = new CustomEvent('showRestoreNotification', {
                    detail: {
                        messageCount: savedData.messages.length,
                        lastSaved: savedData.lastSaved
                    }
                });
                window.dispatchEvent(event);
            }
        }, 1000);
        </script>
        """, unsafe_allow_html=True)

def get_system_prompt():
    """è·å–ç³»ç»Ÿæç¤ºè¯"""
    return f"""
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- å›ç­”å‡†ç¡®ã€æœ‰å¸®åŠ©
- è¯­è¨€è¡¨è¾¾æ¸…æ™°æ˜“æ‡‚
- èƒ½å¤Ÿå¤„ç†å„ç§ç±»å‹çš„é—®é¢˜
- ä¿æŒç¤¼è²Œå’Œä¸“ä¸šçš„æ€åº¦
- æ€»æ˜¯ç”¨ä¸­æ–‡å›å¤

å½“å‰ç”¨æˆ·ï¼šKikyo-acd
å½“å‰æ—¶é—´ï¼š2025-08-08 09:57:08 (UTC)

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›æœ€æœ‰ä»·å€¼çš„å›ç­”ã€‚
"""

def call_ai_api(user_message, model_id, api_key):
    """è°ƒç”¨AI APIè¿›è¡Œå¯¹è¯"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    messages = [{"role": "system", "content": get_system_prompt()}]

    # æ·»åŠ æœ€è¿‘çš„èŠå¤©å†å²
    if st.session_state.chat_messages:
        recent_messages = st.session_state.chat_messages[-10:]
        for msg in recent_messages:
            if msg['role'] in ['user', 'assistant']:
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })

    messages.append({"role": "user", "content": user_message})

    payload = {
        "messages": messages,
        "model": model_id,
        "max_tokens": 2000,
        "temperature": 0.7
    }

    try:
        response = requests.post(
            "https://models.inference.ai.azure.com/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            return result['choices'][0]['message']['content'], True
        elif response.status_code == 401:
            return "âŒ APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥", False
        elif response.status_code == 404:
            return f"âŒ æ¨¡å‹ {model_id} ä¸å¯ç”¨", False
        else:
            return f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}", False

    except Exception as e:
        return f"âŒ è¿æ¥é”™è¯¯: {str(e)[:100]}", False

def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("# ğŸ¤– AIå¯¹è¯æ§åˆ¶å°")
        
        # APIé…ç½®åŒºåŸŸ
        st.markdown("### ğŸ”§ APIé…ç½®")
        api_key = st.text_input(
            "GitHub Models APIå¯†é’¥",
            value=st.session_state.github_api_key,
            type="password",
            placeholder="è¾“å…¥æ‚¨çš„APIå¯†é’¥..."
        )
        
        if api_key != st.session_state.github_api_key:
            st.session_state.github_api_key = api_key
            st.session_state.models_loaded = False
        
        # APIçŠ¶æ€æ˜¾ç¤º
        if st.session_state.github_api_key:
            st.markdown("""
            <div class="status-indicator status-connected">
                <div class="status-dot dot-online"></div>
                <span>APIå·²è¿æ¥</span>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="status-indicator status-disconnected">
                <div class="status-dot dot-offline"></div>
                <span>è¯·è¾“å…¥APIå¯†é’¥</span>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # æ¨¡å‹é€‰æ‹©åŒºåŸŸ
        st.markdown("### ğŸ¯ é€‰æ‹©AIæ¨¡å‹")
        
        if not st.session_state.models_loaded:
            if st.session_state.github_api_key:
                with st.spinner("æ£€æµ‹å¯ç”¨æ¨¡å‹..."):
                    all_models = get_all_supported_models()
                    available_models = []
                    
                    # æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§
                    for model in all_models:
                        if test_model_availability(st.session_state.github_api_key, model['id']):
                            available_models.append(model)
                    
                    st.session_state.available_models = available_models if available_models else all_models
                    st.session_state.models_loaded = True
                    st.rerun()
            else:
                st.session_state.available_models = get_all_supported_models()
                st.session_state.models_loaded = True
        
        # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„æ¨¡å‹
        current_model = next((m for m in st.session_state.available_models 
                            if m['id'] == st.session_state.selected_model), None)
        if current_model:
            st.info(f"å½“å‰æ¨¡å‹ï¼š**{current_model['name']}**")
        
        # æ¨¡å‹åˆ—è¡¨
        for model in st.session_state.available_models:
            is_selected = model['id'] == st.session_state.selected_model
            
            # æ„å»ºæ ‡ç­¾
            tags_html = ""
            for tag in model['tags']:
                tag_class = ""
                if tag in ['æœ€æ–°', 'é«˜è´¨é‡', 'å¤šæ¨¡æ€']:
                    tag_class = "premium"
                elif tag in ['å¿«é€Ÿ', 'ç»æµ', 'è½»é‡']:
                    tag_class = "fast"
                elif tag in ['æ¨è']:
                    tag_class = "recommended"
                
                tags_html += f'<span class="model-tag {tag_class}">{tag}</span>'
            
            # æ¨¡å‹å¡ç‰‡
            card_class = "model-card selected" if is_selected else "model-card"
            st.markdown(f"""
            <div class="{card_class}">
                <div class="model-name">{model['name']}</div>
                <div class="model-description">{model['description']}</div>
                <div class="model-tags">{tags_html}</div>
            </div>
            """, unsafe_allow_html=True)
            
            # é€‰æ‹©æŒ‰é’®
            if st.button(
                f"{'âœ“ å·²é€‰æ‹©' if is_selected else f'é€‰æ‹© {model[\"name\"]}'}",
                key=f"select_{model['id']}",
                disabled=is_selected,
                use_container_width=True
            ):
                st.session_state.selected_model = model['id']
                st.success(f"âœ… å·²åˆ‡æ¢åˆ° {model['name']}")
                save_chat_data()  # ä¿å­˜æ¨¡å‹é€‰æ‹©
                st.rerun()
        
        st.markdown("---")
        
        # æ•°æ®ç®¡ç†åŒºåŸŸ
        st.markdown("### ğŸ’¾ æ•°æ®ç®¡ç†")
        
        # å­˜å‚¨çŠ¶æ€
        if st.session_state.chat_messages:
            message_count = len(st.session_state.chat_messages)
            st.markdown(f"ğŸ“Š èŠå¤©è®°å½•ï¼š{message_count} æ¡")
        
        # è‡ªåŠ¨ä¿å­˜å¼€å…³
        auto_save = st.checkbox(
            "ğŸ”„ è‡ªåŠ¨ä¿å­˜",
            value=st.session_state.get('auto_save_enabled', True),
            help="æ¯æ¬¡å¯¹è¯åè‡ªåŠ¨ä¿å­˜åˆ°æµè§ˆå™¨"
        )
        st.session_state.auto_save_enabled = auto_save
        
        # æ•°æ®æ“ä½œæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜", use_container_width=True):
                save_chat_data()
                st.success("å·²ä¿å­˜åˆ°æœ¬åœ°")
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•", use_container_width=True):
                st.session_state.chat_messages = []
                st.session_state.conversation_count = 0
                # æ¸…ç©ºæœ¬åœ°å­˜å‚¨
                st.markdown("""
                <script>
                if (window.ChatStorage) {
                    window.ChatStorage.clear();
                }
                </script>
                """, unsafe_allow_html=True)
                st.success("è®°å½•å·²æ¸…ç©º")
                st.rerun()
        
        # å¯¼å‡ºåŠŸèƒ½
        if st.session_state.chat_messages:
            export_data = {
                'export_time': datetime.now().isoformat(),
                'model_used': st.session_state.selected_model,
                'message_count': len(st.session_state.chat_messages),
                'messages': st.session_state.chat_messages
            }
            
            st.download_button(
                "ğŸ“¤ å¯¼å‡ºJSON",
                json.dumps(export_data, ensure_ascii=False, indent=2),
                file_name=f"ai_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
        
        st.markdown("---")
        
        # ç»Ÿè®¡ä¿¡æ¯
        st.markdown("### ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
        st.markdown(f"å¯¹è¯è½®æ•°ï¼š{st.session_state.conversation_count}")
        st.markdown(f"å½“å‰ç”¨æˆ·ï¼šKikyo-acd")
        st.markdown(f"æ—¶é—´ï¼š2025-08-08 09:57:08")

def render_main_content():
    """æ¸²æŸ“ä¸»è¦å†…å®¹åŒºåŸŸ"""
    # é¡µé¢æ ‡é¢˜
    st.markdown("""
    <div class="main-title">ğŸ¤– AIæ™ºèƒ½å¯¹è¯å¹³å°</div>
    <div class="subtitle">æ”¯æŒå¤šç§AIæ¨¡å‹çš„æ™ºèƒ½å¯¹è¯ä½“éªŒ</div>
    """, unsafe_allow_html=True)
    
    # æ¢å¤æ•°æ®æç¤º
    restore_chat_data()
    
    # èŠå¤©å†å²æ˜¾ç¤º
    if st.session_state.chat_messages:
        st.markdown("### ğŸ’¬ å¯¹è¯è®°å½•")
        
        # åˆ›å»ºèŠå¤©å®¹å™¨
        chat_container = st.container()
        with chat_container:
            for msg in st.session_state.chat_messages:
                timestamp = time.strftime("%H:%M", time.localtime(msg.get('timestamp', time.time())))
                model_used = msg.get('model', 'æœªçŸ¥æ¨¡å‹')
                
                if msg['role'] == 'user':
                    st.markdown(f"""
                    <div class="user-message">
                        {msg['content']}
                        <div class="message-time">{timestamp}</div>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="ai-message">
                        <div class="message-model">ğŸ¤– {model_used}</div>
                        {msg['content']}
                        <div class="message-time">{timestamp}</div>
                    </div>
                    """, unsafe_allow_html=True)
    
    # è¾“å…¥åŒºåŸŸ
    st.markdown("### âœ¨ å¼€å§‹å¯¹è¯")
    
    # æ˜¾ç¤ºå½“å‰æ¨¡å‹
    current_model = next((m for m in st.session_state.available_models 
                        if m['id'] == st.session_state.selected_model), None)
    if current_model:
        st.info(f"å½“å‰ä½¿ç”¨æ¨¡å‹ï¼š**{current_model['name']}** - {current_model['description']}")
    
    user_input = st.text_area(
        "",
        placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æƒ³æ³•...",
        height=100,
        key="chat_input",
        label_visibility="collapsed"
    )

    col1, col2, col3 = st.columns([3, 1, 1])
    
    with col1:
        send_disabled = not st.session_state.github_api_key
        if st.button("ğŸš€ å‘é€æ¶ˆæ¯", use_container_width=True, type="primary", disabled=send_disabled):
            if not st.session_state.github_api_key:
                st.error("è¯·åœ¨ä¾§è¾¹æ é…ç½®APIå¯†é’¥")
            elif user_input.strip():
                process_chat_message(user_input.strip())
                st.rerun()
            else:
                st.warning("è¯·è¾“å…¥å†…å®¹")

    with col2:
        if st.button("ğŸ² éšæœºè¯é¢˜", use_container_width=True, disabled=send_disabled):
            if st.session_state.github_api_key:
                topics = [
                    "ç»™æˆ‘è®²ä¸€ä¸ªæœ‰è¶£çš„ç§‘å­¦äº‹å®",
                    "æ¨èä¸€æœ¬å€¼å¾—è¯»çš„ä¹¦",
                    "è§£é‡Šä¸€ä¸‹äººå·¥æ™ºèƒ½çš„åŸç†",
                    "åˆ›ä½œä¸€é¦–å…³äºç§‹å¤©çš„è¯—",
                    "åˆ†æä¸€ä¸‹å½“å‰çš„ç§‘æŠ€è¶‹åŠ¿"
                ]
                random_topic = random.choice(topics)
                process_chat_message(random_topic)
            else:
                st.error("è¯·å…ˆé…ç½®APIå¯†é’¥")

    with col3:
        if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹", use_container_width=True):
            st.session_state.models_loaded = False
            st.rerun()

def process_chat_message(user_message):
    """å¤„ç†èŠå¤©æ¶ˆæ¯"""
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.chat_messages.append({
        'role': 'user',
        'content': user_message,
        'timestamp': time.time(),
        'model': st.session_state.selected_model
    })

    # æ˜¾ç¤ºæ€è€ƒåŠ¨ç”»
    thinking_placeholder = st.empty()
    current_model_name = next((m['name'] for m in st.session_state.available_models 
                             if m['id'] == st.session_state.selected_model), 
                            st.session_state.selected_model)
    
    with thinking_placeholder:
        st.markdown(f"""
        <div class="typing-indicator">
            <span>{current_model_name} æ­£åœ¨æ€è€ƒ</span>
            <div class="typing-dots">
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
                <div class="typing-dot"></div>
            </div>
        </div>
        """, unsafe_allow_html=True)

    # è·å–AIå“åº”
    ai_response, success = call_ai_api(
        user_message, st.session_state.selected_model, st.session_state.github_api_key
    )

    thinking_placeholder.empty()

    # æ·»åŠ AIå“åº”
    st.session_state.chat_messages.append({
        'role': 'assistant',
        'content': ai_response,
        'timestamp': time.time(),
        'model': current_model_name
    })

    # æ›´æ–°ç»Ÿè®¡
    st.session_state.conversation_count += 1

    # è‡ªåŠ¨ä¿å­˜
    save_chat_data()

    if success:
        st.success(f"âœ… {current_model_name} å›å¤å·²ç”Ÿæˆå¹¶ä¿å­˜")
    else:
        st.error(f"âŒ {current_model_name} ç”Ÿæˆå¤±è´¥")

def main():
    """ä¸»ç¨‹åº"""
    # åº”ç”¨æ ·å¼
    apply_styles()
    
    # åˆå§‹åŒ–
    initialize_session_state()
    
    # æ¸²æŸ“ç•Œé¢
    render_sidebar()
    render_main_content()

if __name__ == "__main__":
    main()
