import streamlit as st
import openai
import requests
import json
import time
import pandas as pd
import plotly.express as px
from datetime import datetime
import tiktoken
import os
from typing import List, Dict, Optional
import streamlit as st
import requests
import json
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Chat é•œåƒç«™",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
.main-header {
    font-size: 3rem;
    font-weight: bold;
    text-align: center;
    background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 2rem;
}

.feature-card {
    background: #f0f2f6;
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
    border-left: 4px solid #4ECDC4;
}

.status-good {
    color: #28a745;
    font-weight: bold;
}

.status-error {
    color: #dc3545;
    font-weight: bold;
}

.chat-message {
    padding: 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
}

.user-message {
    background-color: #e3f2fd;
    border-left: 4px solid #2196f3;
}

.assistant-message {
    background-color: #f3e5f5;
    border-left: 4px solid #9c27b0;
}
</style>
""", unsafe_allow_html=True)

class AIService:
    def __init__(self):
        self.base_url = None
        self.api_key = None
        self.client = None
        self.available_models = []
        
    def initialize_client(self, api_key: str, base_url: str):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            self.api_key = api_key
            self.base_url = base_url
            self.client = openai.OpenAI(
                api_key=api_key,
                base_url=base_url
            )
            return True
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")
            return False
    
    def fetch_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            if not self.client:
                return []
            
            response = self.client.models.list()
            models = [model.id for model in response.data]
            self.available_models = sorted(models)
            return self.available_models
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥çŠ¶æ€"""
        try:
            if not self.client:
                return False
            
            # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨æ¥æµ‹è¯•è¿æ¥
            self.client.models.list()
            return True
        except Exception as e:
            st.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def chat_completion(self, messages: List[Dict], model: str, **kwargs) -> Optional[str]:
        """å‘é€èŠå¤©è¯·æ±‚"""
        try:
            if not self.client:
                return None
            
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                **kwargs
            )
            return response.choices[0].message.content
        except Exception as e:
            st.error(f"èŠå¤©è¯·æ±‚å¤±è´¥: {str(e)}")
            return None

def count_tokens(text: str, model: str = "gpt-3.5-turbo") -> int:
    """è®¡ç®—tokenæ•°é‡"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except:
        # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼Œä½¿ç”¨è¿‘ä¼¼è®¡ç®—
        return len(text.split()) * 1.3

def get_preset_prompts() -> Dict[str, str]:
    """è·å–é¢„è®¾æç¤ºè¯"""
    return {
        "ğŸ’¼ ä¸“ä¸šåŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨å‡†ç¡®ã€æ¸…æ™°ã€æœ‰æ¡ç†çš„æ–¹å¼å›ç­”é—®é¢˜ã€‚",
        "ğŸ¨ åˆ›æ„å†™ä½œ": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„å†™ä½œåŠ©æ‰‹ï¼Œè¯·å¸®åŠ©ç”¨æˆ·è¿›è¡Œåˆ›æ„å†™ä½œï¼ŒåŒ…æ‹¬æ•…äº‹ã€è¯—æ­Œã€å‰§æœ¬ç­‰ã€‚",
        "ğŸ’» ç¼–ç¨‹ä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ç¼–ç¨‹ä¸“å®¶ï¼Œç²¾é€šå¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œè¯·å¸®åŠ©ç”¨æˆ·è§£å†³ç¼–ç¨‹é—®é¢˜ã€‚",
        "ğŸ“š å­¦ä¹ å¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„å­¦ä¹ å¯¼å¸ˆï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼è§£é‡Šå¤æ‚æ¦‚å¿µï¼Œå¹¶æä¾›å­¦ä¹ å»ºè®®ã€‚",
        "ğŸŒ ç¿»è¯‘åŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œè¯·å‡†ç¡®ç¿»è¯‘ç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œå¹¶è§£é‡Šè¯­è¨€ç»†èŠ‚ã€‚",
        "ğŸ§  åˆ†æä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ªé€»è¾‘æ€ç»´æ¸…æ™°çš„åˆ†æä¸“å®¶ï¼Œè¯·å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œæ·±å…¥åˆ†æå¹¶æä¾›è§è§£ã€‚",
        "ğŸ¯ äº§å“ç»ç†": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„äº§å“ç»ç†ï¼Œè¯·ä»äº§å“è§’åº¦åˆ†æé—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚",
        "ğŸ“Š æ•°æ®åˆ†æå¸ˆ": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œè¯·å¸®åŠ©ç”¨æˆ·åˆ†ææ•°æ®å¹¶æä¾›æ´å¯Ÿã€‚"
    }

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'ai_service' not in st.session_state:
        st.session_state.ai_service = AIService()
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if 'conversation_count' not in st.session_state:
        st.session_state.conversation_count = 0
    
    if 'total_tokens' not in st.session_state:
        st.session_state.total_tokens = 0
    
    if 'settings' not in st.session_state:
        st.session_state.settings = {
            'temperature': 0.7,
            'max_tokens': 2048,
            'top_p': 1.0,
            'frequency_penalty': 0.0,
            'presence_penalty': 0.0
        }

def call_github_models_api(user_message, system_prompt, api_key):
    """è°ƒç”¨GitHub Models APIè¿›è¡Œå¯¹è¯ - ä¿®æ­£ç‰ˆæœ¬"""
    
    # GitHub Models APIçš„æ­£ç¡®ç«¯ç‚¹
    url = "https://models.inference.ai.azure.com/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "User-Agent": "Chinese-Medicine-App/1.0"
    }

    # æ„å»ºå¯¹è¯æ¶ˆæ¯
    messages = [
        {"role": "system", "content": system_prompt}
    ]
    
    # æ·»åŠ èŠå¤©å†å²ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘3è½®å¯¹è¯ï¼‰
    if len(st.session_state.chat_messages) > 0:
        recent_messages = st.session_state.chat_messages[-6:]  # æœ€è¿‘3è½®å¯¹è¯
        for msg in recent_messages:
            messages.append({
                "role": msg['role'],
                "content": msg['content']
            })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": user_message})

    payload = {
        "messages": messages,
        "model": "gpt-4o-mini",  # GitHub Modelsæ”¯æŒçš„æ¨¡å‹
        "max_tokens": 1500,
        "temperature": 0.7,
        "top_p": 0.95,
        "frequency_penalty": 0,
        "presence_penalty": 0
    }

    try:
        response = requests.post(
            url,
            headers=headers,
            json=payload,
            timeout=30
        )
        
        # è¯¦ç»†çš„é”™è¯¯å¤„ç†
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                ai_response = result['choices'][0]['message']['content']
                return f"ğŸ¤– **GitHub CopilotåŠ©æ‰‹ï¼š**\n\n{ai_response}"
            else:
                return "âŒ **å“åº”æ ¼å¼é”™è¯¯**ï¼šAPIè¿”å›æ•°æ®æ ¼å¼ä¸æ­£ç¡®"
                
        elif response.status_code == 401:
            return "âŒ **è®¤è¯å¤±è´¥**ï¼šGitHub APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸã€‚è¯·æ£€æŸ¥æ‚¨çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚"
            
        elif response.status_code == 403:
            return "âŒ **æƒé™ä¸è¶³**ï¼šAPIå¯†é’¥æ²¡æœ‰è®¿é—®GitHub Modelsçš„æƒé™ã€‚è¯·æ£€æŸ¥æ‚¨çš„è®¢é˜…çŠ¶æ€ã€‚"
            
        elif response.status_code == 429:
            return "â° **è¯·æ±‚é™åˆ¶**ï¼šè¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚"
            
        elif response.status_code == 400:
            try:
                error_detail = response.json()
                return f"âŒ **è¯·æ±‚é”™è¯¯**ï¼š{error_detail.get('error', {}).get('message', 'è¯·æ±‚æ ¼å¼ä¸æ­£ç¡®')}"
            except:
                return f"âŒ **è¯·æ±‚é”™è¯¯**ï¼š{response.text[:200]}"
                
        elif response.status_code == 500:
            return "âŒ **æœåŠ¡å™¨é”™è¯¯**ï¼šGitHub ModelsæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            
        else:
            return f"âŒ **æœªçŸ¥é”™è¯¯**ï¼šçŠ¶æ€ç  {response.status_code}\né”™è¯¯ä¿¡æ¯ï¼š{response.text[:300]}"

    except requests.exceptions.Timeout:
        return "â° **è¯·æ±‚è¶…æ—¶**ï¼šç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚"
        
    except requests.exceptions.ConnectionError:
        return "ğŸ”Œ **è¿æ¥é”™è¯¯**ï¼šæ— æ³•è¿æ¥åˆ°GitHub Models APIï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"
        
    except requests.exceptions.RequestException as e:
        return f"âŒ **ç½‘ç»œé”™è¯¯**ï¼š{str(e)[:200]}"
        
    except Exception as e:
        return f"âŒ **æœªçŸ¥é”™è¯¯**ï¼š{str(e)[:200]}"

def test_github_api_connection(api_key):
    """æµ‹è¯•GitHub APIè¿æ¥"""
    if not api_key.strip():
        return False, "APIå¯†é’¥ä¸ºç©º"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # ä½¿ç”¨ç®€å•çš„æµ‹è¯•è¯·æ±‚
    test_payload = {
        "messages": [{"role": "user", "content": "Hello"}],
        "model": "gpt-4o-mini",
        "max_tokens": 10
    }
    
    try:
        response = requests.post(
            "https://models.inference.ai.azure.com/chat/completions",
            headers=headers,
            json=test_payload,
            timeout=10
        )
        
        if response.status_code == 200:
            return True, "è¿æ¥æˆåŠŸ"
        elif response.status_code == 401:
            return False, "APIå¯†é’¥æ— æ•ˆ"
        elif response.status_code == 403:
            return False, "æƒé™ä¸è¶³"
        else:
            return False, f"è¿æ¥å¤±è´¥ï¼š{response.status_code}"
            
    except Exception as e:
        return False, f"è¿æ¥æµ‹è¯•å¤±è´¥ï¼š{str(e)[:100]}"

def render_chat_interface():
    """æ¸²æŸ“èŠå¤©ç•Œé¢ - ä¿®æ­£ç‰ˆæœ¬"""
    with st.sidebar:
        st.markdown("---")
        with st.expander("ğŸ¤– GitHub CopilotåŠ©æ‰‹", expanded=False):
            # APIå¯†é’¥è¾“å…¥å’Œæµ‹è¯•
            st.write("**ğŸ”‘ GitHub APIé…ç½®ï¼š**")
            api_key_input = st.text_input(
                "GitHub Models APIå¯†é’¥",
                value=st.session_state.get('github_api_key', ''),
                type="password",
                placeholder="ghp_xxxxxxxxxxxxxxxxxxxx",
                help="è¯·è¾“å…¥æ‚¨çš„GitHub Models APIå¯†é’¥"
            )

            if api_key_input != st.session_state.get('github_api_key', ''):
                st.session_state.github_api_key = api_key_input

            # APIè¿æ¥æµ‹è¯•æŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ” æµ‹è¯•è¿æ¥", use_container_width=True):
                    if st.session_state.get('github_api_key'):
                        with st.spinner("æµ‹è¯•ä¸­..."):
                            success, message = test_github_api_connection(st.session_state.github_api_key)
                            if success:
                                st.success(f"âœ… {message}")
                            else:
                                st.error(f"âŒ {message}")
                    else:
                        st.error("è¯·å…ˆè¾“å…¥APIå¯†é’¥")

            with col2:
                # APIçŠ¶æ€æ˜¾ç¤º
                if st.session_state.get('github_api_key'):
                    st.success("âœ… å¯†é’¥å·²è¾“å…¥")
                else:
                    st.warning("âš ï¸ è¯·è¾“å…¥å¯†é’¥")

            # ä½¿ç”¨è¯´æ˜
            with st.expander("ğŸ“– APIå¯†é’¥è·å–è¯´æ˜"):
                st.markdown("""
                **è·å–GitHub Models APIå¯†é’¥ï¼š**
                
                1. è®¿é—® [GitHub Settings](https://github.com/settings/tokens)
                2. ç‚¹å‡» "Generate new token" â†’ "Generate new token (classic)"
                3. é€‰æ‹©æƒé™èŒƒå›´ï¼Œè‡³å°‘éœ€è¦ `repo` æƒé™
                4. ç”Ÿæˆå¹¶å¤åˆ¶tokenï¼ˆæ ¼å¼ï¼šghp_xxxxxxï¼‰
                5. ç¡®ä¿æ‚¨çš„è´¦æˆ·æœ‰GitHub Modelsè®¿é—®æƒé™
                
                **æ³¨æ„ï¼š** APIå¯†é’¥åªåœ¨å½“å‰ä¼šè¯æœ‰æ•ˆï¼Œè¯·å¦¥å–„ä¿ç®¡ã€‚
                """)

            # å¿«é€Ÿé—®é¢˜æŒ‰é’®
            st.write("**ğŸ’¡ å¿«é€Ÿå’¨è¯¢ï¼š**")
            suggestions = get_smart_suggestions()

            for suggestion in suggestions[:3]:
                if st.button(suggestion, key=f"suggest_{hash(suggestion)}", use_container_width=True):
                    if st.session_state.get('github_api_key'):
                        process_chat_message(suggestion)
                    else:
                        st.error("è¯·å…ˆè¾“å…¥å¹¶æµ‹è¯•GitHub APIå¯†é’¥")

            # è‡ªå®šä¹‰è¾“å…¥
            st.write("**ğŸ’¬ è‡ªå®šä¹‰é—®é¢˜ï¼š**")
            user_input = st.text_area(
                "",
                placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...\nä¾‹å¦‚ï¼šä¼˜åŒ–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ",
                height=80,
                key="chat_input"
            )

            if st.button("ğŸ“¤ å‘é€", key="send_chat", use_container_width=True, type="primary"):
                if not st.session_state.get('github_api_key'):
                    st.error("è¯·å…ˆè¾“å…¥GitHub APIå¯†é’¥")
                elif user_input.strip():
                    process_chat_message(user_input.strip())
                else:
                    st.warning("è¯·è¾“å…¥é—®é¢˜å†…å®¹")

            # å¯¹è¯å†å²
            if st.session_state.get('chat_messages'):
                st.write("**ğŸ“ æœ€è¿‘å¯¹è¯ï¼š**")
                recent_messages = st.session_state.chat_messages[-4:]
                for msg in recent_messages:
                    if msg['role'] == 'user':
                        st.markdown(f"**ğŸ™‹ æ‚¨ï¼š** {msg['content'][:50]}...")
                    else:
                        # åªæ˜¾ç¤ºå›å¤çš„å‰50ä¸ªå­—ç¬¦
                        content_preview = msg['content'].replace('ğŸ¤– **GitHub CopilotåŠ©æ‰‹ï¼š**\n\n', '')[:50]
                        st.markdown(f"**ğŸ¤– åŠ©æ‰‹ï¼š** {content_preview}...")

                if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", key="clear_chat"):
                    st.session_state.chat_messages = []
                    st.rerun()


def process_chat_message(user_message):
    """å¤„ç†èŠå¤©æ¶ˆæ¯ - ä¿®æ­£ç‰ˆæœ¬"""
    # æ£€æŸ¥APIå¯†é’¥
    if not st.session_state.get('github_api_key', '').strip():
        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„GitHub APIå¯†é’¥")
        return

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
        
    st.session_state.chat_messages.append({
        'role': 'user',
        'content': user_message,
        'timestamp': time.time()
    })

    # è·å–å“åº”
    with st.spinner('ğŸ¤– GitHub Copilotæ€è€ƒä¸­...'):
        system_prompt = get_system_prompt()
        
        # ä½¿ç”¨ä¿®æ­£åçš„APIè°ƒç”¨
        ai_response = call_github_models_api(
            user_message, 
            system_prompt, 
            st.session_state.github_api_key
        )

        # å¦‚æœGitHub APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ™ºèƒ½å“åº”ä½œä¸ºå¤‡ç”¨
        if "âŒ" in ai_response:
            ai_response += f"\n\n---\n\n**ğŸ’¡ æœ¬åœ°å»ºè®®ï¼š**\n\n{get_contextual_response(user_message)}"

    # æ·»åŠ AIå“åº”
    st.session_state.chat_messages.append({
        'role': 'assistant',
        'content': ai_response,
        'timestamp': time.time()
    })

    # æ˜¾ç¤ºæœ€æ–°å›å¤
    st.success("âœ… å›å¤å·²ç”Ÿæˆï¼")

    # è‡ªåŠ¨å±•å¼€èŠå¤©æ¡†æ˜¾ç¤ºç»“æœ
    with st.expander("ğŸ’¬ æœ€æ–°å›å¤", expanded=True):
        st.markdown(ai_response)



def main():
    initialize_session_state()
    
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ¤– AI Chat é•œåƒç«™</h1>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®è®¾ç½®")
        
        # APIé…ç½®
        st.subheader("ğŸ”‘ API é…ç½®")
        api_key = st.text_input("API Key", type="password", value="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")
        base_url = st.text_input("Base URL", value="https://api.openai.com/v1")
        
        if st.button("ğŸ”„ è¿æ¥æµ‹è¯•"):
            if api_key and base_url:
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    if st.session_state.ai_service.initialize_client(api_key, base_url):
                        if st.session_state.ai_service.test_connection():
                            st.success("âœ… è¿æ¥æˆåŠŸï¼")
                            # è·å–æ¨¡å‹åˆ—è¡¨
                            models = st.session_state.ai_service.fetch_models()
                            if models:
                                st.success(f"âœ… è·å–åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹")
                        else:
                            st.error("âŒ è¿æ¥å¤±è´¥")
            else:
                st.warning("âš ï¸ è¯·å¡«å†™API Keyå’ŒBase URL")
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¯ æ¨¡å‹é€‰æ‹©")
        if st.session_state.ai_service.available_models:
            selected_model = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                st.session_state.ai_service.available_models,
                index=0 if st.session_state.ai_service.available_models else None
            )
        else:
            selected_model = st.text_input("æ¨¡å‹åç§°", value="gpt-3.5-turbo")
            if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨"):
                if st.session_state.ai_service.client:
                    models = st.session_state.ai_service.fetch_models()
                    if models:
                        st.rerun()
        
        # é«˜çº§è®¾ç½®
        st.subheader("ğŸ› ï¸ é«˜çº§è®¾ç½®")
        with st.expander("å‚æ•°è°ƒèŠ‚"):
            st.session_state.settings['temperature'] = st.slider(
                "Temperature (åˆ›é€ æ€§)", 0.0, 2.0, 
                st.session_state.settings['temperature'], 0.1
            )
            st.session_state.settings['max_tokens'] = st.slider(
                "Max Tokens", 1, 4096, 
                st.session_state.settings['max_tokens']
            )
            st.session_state.settings['top_p'] = st.slider(
                "Top P", 0.0, 1.0, 
                st.session_state.settings['top_p'], 0.1
            )
            st.session_state.settings['frequency_penalty'] = st.slider(
                "Frequency Penalty", -2.0, 2.0, 
                st.session_state.settings['frequency_penalty'], 0.1
            )
            st.session_state.settings['presence_penalty'] = st.slider(
                "Presence Penalty", -2.0, 2.0, 
                st.session_state.settings['presence_penalty'], 0.1
            )
        
        # ç»Ÿè®¡ä¿¡æ¯
        st.subheader("ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
        st.metric("å¯¹è¯æ¬¡æ•°", st.session_state.conversation_count)
        st.metric("æ€»Tokenæ•°", st.session_state.total_tokens)
        
        # æ“ä½œæŒ‰é’®
        st.subheader("ğŸ”§ æ“ä½œ")
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.session_state.conversation_count = 0
            st.session_state.total_tokens = 0
            st.rerun()
        
        if st.button("ğŸ’¾ å¯¼å‡ºå¯¹è¯"):
            if st.session_state.chat_history:
                export_data = {
                    "timestamp": datetime.now().isoformat(),
                    "conversation_count": st.session_state.conversation_count,
                    "total_tokens": st.session_state.total_tokens,
                    "chat_history": st.session_state.chat_history
                }
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½JSONæ–‡ä»¶",
                    json.dumps(export_data, ensure_ascii=False, indent=2),
                    file_name=f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ å¯¹è¯åŒºåŸŸ")
        
        # é¢„è®¾æç¤ºè¯
        st.subheader("ğŸ­ é¢„è®¾è§’è‰²")
        preset_prompts = get_preset_prompts()
        
        cols = st.columns(4)
        for i, (name, prompt) in enumerate(preset_prompts.items()):
            with cols[i % 4]:
                if st.button(name, key=f"preset_{i}"):
                    # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
                    if not st.session_state.chat_history or st.session_state.chat_history[0]["role"] != "system":
                        st.session_state.chat_history.insert(0, {
                            "role": "system",
                            "content": prompt,
                            "timestamp": datetime.now().strftime("%H:%M:%S")
                        })
                    else:
                        st.session_state.chat_history[0]["content"] = prompt
                    st.rerun()
        
        # è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
        custom_system_prompt = st.text_area(
            "ğŸ¯ è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯",
            placeholder="è¾“å…¥è‡ªå®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯æ¥å®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸º...",
            height=100
        )
        
        if st.button("ğŸ¯ è®¾ç½®ç³»ç»Ÿæç¤ºè¯") and custom_system_prompt:
            if not st.session_state.chat_history or st.session_state.chat_history[0]["role"] != "system":
                st.session_state.chat_history.insert(0, {
                    "role": "system",
                    "content": custom_system_prompt,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                })
            else:
                st.session_state.chat_history[0]["content"] = custom_system_prompt
            st.success("âœ… ç³»ç»Ÿæç¤ºè¯å·²è®¾ç½®")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        st.subheader("ğŸ“ å¯¹è¯å†å²")
        chat_container = st.container()
        
        with chat_container:
            for i, message in enumerate(st.session_state.chat_history):
                if message["role"] == "system":
                    with st.expander(f"ğŸ¯ ç³»ç»Ÿæç¤ºè¯ ({message.get('timestamp', '')})"):
                        st.write(message["content"])
                elif message["role"] == "user":
                    st.markdown(f"""
                    <div class="chat-message user-message">
                        <strong>ğŸ‘¤ ç”¨æˆ· ({message.get('timestamp', '')}):</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="chat-message assistant-message">
                        <strong>ğŸ¤– åŠ©æ‰‹ ({message.get('timestamp', '')}):</strong><br>
                        {message["content"]}
                    </div>
                    """, unsafe_allow_html=True)
        
        # ç”¨æˆ·è¾“å…¥
        st.subheader("ğŸ’­ å‘é€æ¶ˆæ¯")
        
        # å¤šç§è¾“å…¥æ–¹å¼
        input_method = st.radio("è¾“å…¥æ–¹å¼", ["ğŸ’¬ æ™®é€šè¾“å…¥", "ğŸ“ å¤šè¡Œè¾“å…¥", "ğŸ¤ è¯­éŸ³è¾“å…¥(æš‚æœªå®ç°)"], horizontal=True)
        
        user_input = ""
        if input_method == "ğŸ’¬ æ™®é€šè¾“å…¥":
            user_input = st.text_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯:", key="user_input_text")
        elif input_method == "ğŸ“ å¤šè¡Œè¾“å…¥":
            user_input = st.text_area("è¾“å…¥æ‚¨çš„æ¶ˆæ¯:", height=150, key="user_input_area")
        
        # å¿«é€Ÿæç¤ºè¯
        st.write("ğŸš€ å¿«é€Ÿæç¤ºè¯:")
        quick_prompts = [
            "è¯·æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„å¯¹è¯",
            "è¯·ç»™æˆ‘ä¸€äº›å»ºè®®",
            "è¯·è¯¦ç»†è§£é‡Šè¿™ä¸ªæ¦‚å¿µ",
            "è¯·ä¸¾ä¸ªä¾‹å­è¯´æ˜",
            "è¯·åˆ—å‡ºè¦ç‚¹",
            "è¯·æ¢ä¸ªè§’åº¦åˆ†æ"
        ]
        
        cols = st.columns(3)
        for i, prompt in enumerate(quick_prompts):
            with cols[i % 3]:
                if st.button(prompt, key=f"quick_{i}"):
                    user_input = prompt
        
        # å‘é€æŒ‰é’®
        col_send, col_clear = st.columns([1, 1])
        with col_send:
            send_clicked = st.button("ğŸš€ å‘é€æ¶ˆæ¯", type="primary")
        with col_clear:
            if st.button("ğŸ§¹ æ¸…ç©ºè¾“å…¥"):
                st.rerun()
        
        # å¤„ç†å‘é€æ¶ˆæ¯
        if send_clicked and user_input and st.session_state.ai_service.client:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.chat_history.append({
                "role": "user",
                "content": user_input,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })
            
            # å‡†å¤‡å‘é€ç»™AIçš„æ¶ˆæ¯
            messages_for_ai = [msg for msg in st.session_state.chat_history if msg["role"] in ["system", "user", "assistant"]]
            messages_for_ai = [{"role": msg["role"], "content": msg["content"]} for msg in messages_for_ai]
            
            # å‘é€è¯·æ±‚
            with st.spinner("ğŸ¤– AIæ­£åœ¨æ€è€ƒä¸­..."):
                response = st.session_state.ai_service.chat_completion(
                    messages=messages_for_ai,
                    model=selected_model,
                    **st.session_state.settings
                )
                
                if response:
                    # æ·»åŠ AIå›å¤
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": response,
                        "timestamp": datetime.now().strftime("%H:%M:%S")
                    })
                    
                    # æ›´æ–°ç»Ÿè®¡
                    st.session_state.conversation_count += 1
                    user_tokens = count_tokens(user_input, selected_model)
                    response_tokens = count_tokens(response, selected_model)
                    st.session_state.total_tokens += user_tokens + response_tokens
                    
                    st.rerun()
        elif send_clicked and not st.session_state.ai_service.client:
            st.error("âŒ è¯·å…ˆé…ç½®å¹¶æµ‹è¯•APIè¿æ¥")
        elif send_clicked and not user_input:
            st.warning("âš ï¸ è¯·è¾“å…¥æ¶ˆæ¯å†…å®¹")
    
    with col2:
        st.header("ğŸ“Š åŠŸèƒ½é¢æ¿")
        
        # è¿æ¥çŠ¶æ€
        st.subheader("ğŸ”Œ è¿æ¥çŠ¶æ€")
        if st.session_state.ai_service.client:
            st.markdown('<p class="status-good">âœ… å·²è¿æ¥</p>', unsafe_allow_html=True)
            if st.session_state.ai_service.available_models:
                st.write(f"ğŸ¯ å¯ç”¨æ¨¡å‹: {len(st.session_state.ai_service.available_models)}ä¸ª")
        else:
            st.markdown('<p class="status-error">âŒ æœªè¿æ¥</p>', unsafe_allow_html=True)
        
        # Tokenä½¿ç”¨æƒ…å†µå›¾è¡¨
        if st.session_state.total_tokens > 0:
            st.subheader("ğŸ“ˆ Tokenä½¿ç”¨è¶‹åŠ¿")
            # ç®€å•çš„ä½¿ç”¨ç»Ÿè®¡ï¼ˆè¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºæ›´è¯¦ç»†çš„å›¾è¡¨ï¼‰
            fig = px.pie(
                values=[st.session_state.total_tokens, max(10000 - st.session_state.total_tokens, 0)],
                names=['å·²ä½¿ç”¨', 'å‰©ä½™'],
                title="Tokenä½¿ç”¨æƒ…å†µ"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # æ¨¡å‹ä¿¡æ¯
        st.subheader("ğŸ¤– å½“å‰æ¨¡å‹")
        if 'selected_model' in locals():
            st.info(f"ğŸ“± **æ¨¡å‹**: {selected_model}")
            st.info(f"ğŸŒ¡ï¸ **Temperature**: {st.session_state.settings['temperature']}")
            st.info(f"ğŸ“ **Max Tokens**: {st.session_state.settings['max_tokens']}")
        
        # å®ç”¨å·¥å…·
        st.subheader("ğŸ› ï¸ å®ç”¨å·¥å…·")
        
        with st.expander("ğŸ“Š å¯¹è¯åˆ†æ"):
            if st.session_state.chat_history:
                user_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "user"])
                assistant_messages = len([msg for msg in st.session_state.chat_history if msg["role"] == "assistant"])
                
                st.write(f"ğŸ‘¤ ç”¨æˆ·æ¶ˆæ¯: {user_messages}")
                st.write(f"ğŸ¤– åŠ©æ‰‹å›å¤: {assistant_messages}")
                st.write(f"ğŸ’¬ æ€»æ¶ˆæ¯æ•°: {len(st.session_state.chat_history)}")
                
                # å­—ç¬¦ç»Ÿè®¡
                total_chars = sum(len(msg["content"]) for msg in st.session_state.chat_history)
                st.write(f"ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars}")
        
        with st.expander("ğŸ¨ ä¸»é¢˜è®¾ç½®"):
            theme = st.selectbox("é€‰æ‹©ä¸»é¢˜", ["é»˜è®¤", "æ·±è‰²", "æµ…è‰²"])
            if theme != "é»˜è®¤":
                st.info("ä¸»é¢˜åŠŸèƒ½å¼€å‘ä¸­...")
        
        with st.expander("ğŸ“‹ å¿«æ·æ“ä½œ"):
            if st.button("ğŸ“‹ å¤åˆ¶æœ€åå›å¤"):
                if st.session_state.chat_history:
                    last_assistant_msg = None
                    for msg in reversed(st.session_state.chat_history):
                        if msg["role"] == "assistant":
                            last_assistant_msg = msg["content"]
                            break
                    if last_assistant_msg:
                        st.code(last_assistant_msg)
                        st.success("âœ… å†…å®¹å·²æ˜¾ç¤ºï¼Œå¯æ‰‹åŠ¨å¤åˆ¶")
            
            if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆå›å¤"):
                if (st.session_state.chat_history and 
                    st.session_state.chat_history[-1]["role"] == "assistant"):
                    # ç§»é™¤æœ€åçš„åŠ©æ‰‹å›å¤
                    st.session_state.chat_history.pop()
                    st.success("âœ… å·²ç§»é™¤æœ€åå›å¤ï¼Œè¯·é‡æ–°å‘é€æ¶ˆæ¯")
        
        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
        st.write(f"ğŸ•’ å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        st.write(f"ğŸ·ï¸ ç‰ˆæœ¬: v1.0.0")
        st.write(f"âš¡ Streamlit: {st.__version__}")

if __name__ == "__main__":
    main()
